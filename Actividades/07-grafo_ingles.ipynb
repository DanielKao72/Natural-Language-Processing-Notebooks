{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56b2f869",
   "metadata": {},
   "source": [
    "### Alumno: Juan Daniel Kao Pech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75b680fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import spacy\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d0d360f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.3/12.8 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.8/12.8 MB 3.3 MB/s eta 0:00:04\n",
      "     ---- ----------------------------------- 1.6/12.8 MB 3.5 MB/s eta 0:00:04\n",
      "     -------- ------------------------------- 2.6/12.8 MB 3.8 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 3.4/12.8 MB 3.7 MB/s eta 0:00:03\n",
      "     ------------ --------------------------- 3.9/12.8 MB 3.6 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 4.2/12.8 MB 3.2 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 4.5/12.8 MB 3.0 MB/s eta 0:00:03\n",
      "     -------------- ------------------------- 4.7/12.8 MB 2.7 MB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 5.2/12.8 MB 2.6 MB/s eta 0:00:03\n",
      "     ------------------- -------------------- 6.3/12.8 MB 2.8 MB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 7.1/12.8 MB 2.9 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 7.6/12.8 MB 2.9 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 8.4/12.8 MB 3.0 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 9.4/12.8 MB 3.1 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 10.2/12.8 MB 3.1 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.0/12.8 MB 3.2 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.8/12.8 MB 3.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.6/12.8 MB 3.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 3.2 MB/s  0:00:04\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33727f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\danik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nltk.download('stopwords') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "908120c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "directorio = \"../Textos de Prueba/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2244543",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lee_xml_eat():\n",
    "    lista_grafos = []\n",
    "    G_freq=nx.Graph()\n",
    "    G_asoc= nx.Graph()\n",
    "    conjunto_nodos = set()\n",
    "    tree = ET.parse(directorio+'eat-stimulus-response.xml')\n",
    "    root = tree.getroot()\n",
    "    todos = 8211\n",
    "    i=0\n",
    "    nodos={}\n",
    "    total = 0\n",
    "    j = 0\n",
    "    for child in root:\n",
    "        estimulo = child.get('word')\n",
    "        total =child.get('all')\n",
    "        estimulo = estimulo.lower()\n",
    "        estimulo = estimulo.replace(\" \",\"_\")\n",
    "        for response in child.iter('response'):\n",
    "            frecuencia = response.get('n')\n",
    "            asociacion = response.get('r')\n",
    "            respuesta = response.get('word')\n",
    "            respuesta = respuesta.lower()\n",
    "            respuesta = respuesta.replace(\" \",\"_\")\n",
    "            if respuesta not in conjunto_nodos:\n",
    "                nodos[respuesta] = j\n",
    "                G_freq.add_node(respuesta)\n",
    "                G_asoc.add_node(respuesta)\n",
    "                conjunto_nodos.add(respuesta)\n",
    "                j+=1\n",
    "            G_freq.add_edge(estimulo,respuesta,weight=float(1/int(frecuencia)))\n",
    "            G_asoc.add_edge(estimulo,respuesta,weight=float(1-float(asociacion)))\n",
    "    lista_grafos.append(G_freq)\n",
    "    lista_grafos.append(G_asoc)\n",
    "    print(\"Grafos creados\")\n",
    "    return lista_grafos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87c2d3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grafos creados\n"
     ]
    }
   ],
   "source": [
    "grafos = lee_xml_eat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78421cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = grafos[0]\n",
    "g2 = grafos[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6db6a9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpia_lematiza(cadena):\n",
    "  limpiado = \"\"\n",
    "  palabras_funcionales = nltk.corpus.stopwords.words('english')\n",
    "  for c in string.punctuation:\n",
    "    cadena = cadena.replace(c, \"\")\n",
    "  cadena = cadena.strip()\n",
    "  for palabra in cadena.split():\n",
    "    if palabra not in palabras_funcionales:\n",
    "      doc = nlp(palabra)\n",
    "      limpiado += doc[0].lemma_ + \" \"\n",
    "  return limpiado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1e9c9ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'entirely new concept '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limpia_lematiza(\"an entirely new concept!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4630516e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conceptos(lista,subconjunto):\n",
    "  datos = []\n",
    "  if len(lista) <= 100:\n",
    "    tope = len(lista)\n",
    "  else:\n",
    "    tope = 100\n",
    "  for x in range(0,tope):\n",
    "    if str(lista[x][0]) not in subconjunto and float(lista[x][1])>0:\n",
    "      datos.append(str(lista[x][0]))\n",
    "  return datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58294021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diccionario_nap(definicion):\n",
    "  grafos = lee_xml_eat()\n",
    "  grafo_frec = grafos[0]\n",
    "  grafo_asociacion = grafos[1]\n",
    "  texto = limpia_lematiza(definicion)\n",
    "  texto = texto.lower()\n",
    "  tokens = texto.split(\" \")\n",
    "  subconjunto_lemas = []\n",
    "  for token in tokens:\n",
    "    if token in grafo_frec.nodes() and token!= \"\":\n",
    "      subconjunto_lemas.append(token)\n",
    "  if len(subconjunto_lemas) > 0:\n",
    "    resultado_asociacion = nx.betweenness_centrality_subset(grafo_asociacion,subconjunto_lemas,subconjunto_lemas,weight=\"weight\",normalized=True)\n",
    "    encontrado = sorted(resultado_asociacion.items(), key=lambda x: x[1], reverse=True)[0:99]\n",
    "    print(\"Asociación\")\n",
    "\n",
    "    print(conceptos(encontrado,subconjunto_lemas))\n",
    "    resultado_asociacion = nx.betweenness_centrality_subset(grafo_frec,subconjunto_lemas,subconjunto_lemas,weight=\"weight\",normalized=True)\n",
    "    encontrado = sorted(resultado_asociacion.items(), key=lambda x: x[1], reverse=True)[0:99]\n",
    "    print(\"Frecuencia\")\n",
    "    print(conceptos(encontrado,subconjunto_lemas))\n",
    "  else:\n",
    "    print(\"Definición muy corta, favor de agregar más datos\")\n",
    "  return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "131b91b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grafos creados\n",
      "Asociación\n",
      "['blue', 'television', 'now', 'dream', 'bright', 'prefer', 'night', 'regard', 'blues', 'prejudice', 'crystals', 'gazers', 'out', 'another']\n",
      "Frecuencia\n",
      "['blue', 'love', 'out', 'see', 'red', 'star', 'cloudy', 'transparent', 'caress', 'kiss', 'lips', 'gazers', 'evening', 'kind', 'night', 'sort', 'appear', \"mother's\", 'compassionate', 'seem']\n"
     ]
    }
   ],
   "source": [
    "diccionario_nap(\"color that looks like the sky on a clear day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d4e29a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grafos creados\n",
      "Asociación\n",
      "['milk', 'soup', 'potato', 'nodules', 'women', 'them', 'often', 'rabbits', 'pints', 'blight', 'nothing', 'sheep', 'energy', 'instead', 'crop', 'bulb', 'fangs', 'consume', 'wives', 'intestines']\n",
      "Frecuencia\n",
      "['up', 'milk', 'potato', 'food', 'good', 'black', 'much', 'mash', 'very', 'beer', 'pint', 'down', 'cat', 'all', 'fish', 'empty', 'money', 'gill', 'broken', 'fill', 'tie', 'fed', 'a_lot', 'flower', 'smashed', 'chips', 'collar', 'most', 'lot', 'vacant', 'pints', 'lily', 'bran', 'vase', 'sausages', 'saucepan', 'plague', 'porcelain', 'dried', 'kitty', 'panther', 'wholesome', 'blight', 'guiness']\n"
     ]
    }
   ],
   "source": [
    "diccionario_nap(\"creamy white tuber that is used in many dishes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ceb7f6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grafos creados\n",
      "Asociación\n",
      "['book', 'expert', 'dictionary', 'kingdom', 'gnu', 'rhino', 'lion', 'warrior']\n",
      "Frecuencia\n",
      "['book', 'see', 'recognize', 'bird', 'caged', 'edition', 'paper', 'dog', 'board', 'queen', 'story', 'red', 'eye', 'notice', 'look', 'fairy', 'hawk', 'penguin', 'lear', 'tale', 'emery', 'crimson', 'setter', 'quadruped']\n"
     ]
    }
   ],
   "source": [
    "diccionario_nap(\"animal known as the king of the jungle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
